Attention
 Master
 By: Alexa Orrico, Software Engineer at Holberton School
 Weight: 5
 Migrated to checker v2: 
 Your score will be updated as you progress.


Resources:
Read or watch:

Attention Model Intuition
Attention Model
How Transformers work in deep learning and NLP: an intuitive introduction
Transformers
Bert, GPT : The Illustrated GPT-2 - Visualizing Transformer Language Models
SQuAD
Glue
Self supervised learning
Learning Objectives
At the end of this project, you are expected to be able to explain to anyone, without the help of Google:

General
What is the attention mechanism?
How to apply attention to RNNs
What is a transformer?
How to create an encoder-decoder transformer model
What is GPT?
What is BERT?
What is self-supervised learning?
How to use BERT for specific NLP tasks
What is SQuAD? GLUE?
Requirements
General
Allowed editors: vi, vim, emacs
All your files will be interpreted/compiled on Ubuntu 20.04 LTS using python3 (version 3.9)
Your files will be executed with numpy (version 1.25.2) and tensorflow (version 2.15)
All your files should end with a new line
The first line of all your files should be exactly #!/usr/bin/env python3
All of your files must be executable
A README.md file, at the root of the folder of the project, is mandatory
Your code should follow the pycodestyle style (version 2.11.1)
All your modules should have documentation (python3 -c 'print(__import__("my_module").__doc__)')
All your classes should have documentation (python3 -c 'print(__import__("my_module").MyClass.__doc__)')
All your functions (inside and outside a class) should have documentation (python3 -c 'print(__import__("my_module").my_function.__doc__)' and python3 -c 'print(__import__("my_module").MyClass.my_function.__doc__)')
Unless otherwise stated, you cannot import any module except import tensorflow as tf
